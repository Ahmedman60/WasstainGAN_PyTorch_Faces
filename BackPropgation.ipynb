{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebbef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e60fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "lr=0.001\n",
    "iteration=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8905979",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3\n",
    "b=1\n",
    "c=1\n",
    "Y_hat=3*(a+(b*c))\n",
    "Y_hat\n",
    "g=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33603a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:weight0 = 0.995, weight1 = 0.022 , weight2 = 0.022  ,loss = 1079.00424\n",
      "epoch 3:weight0 = 1.835, weight1 = 0.049 , weight2 = 0.049  ,loss = 98.36834\n",
      "epoch 5:weight0 = 2.087, weight1 = 0.065 , weight2 = 0.065  ,loss = 8.82648\n",
      "epoch 7:weight0 = 2.162, weight1 = 0.071 , weight2 = 0.071  ,loss = 0.77801\n",
      "epoch 9:weight0 = 2.184, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.06796\n",
      "epoch 11:weight0 = 2.191, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.00592\n",
      "epoch 13:weight0 = 2.193, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.00051\n",
      "epoch 15:weight0 = 2.193, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.00004\n",
      "epoch 17:weight0 = 2.193, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.00000\n",
      "epoch 19:weight0 = 2.194, weight1 = 0.073 , weight2 = 0.073  ,loss = 0.00000\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(5,dtype=torch.float64) #i will consider those as training data\n",
    "b=torch.tensor(3,dtype=torch.float64)\n",
    "c=torch.tensor(2,dtype=torch.float64)\n",
    "Y=torch.tensor(33,dtype=torch.float64)\n",
    "\n",
    "w0=torch.tensor(0.01,dtype=torch.float64,requires_grad=True)\n",
    "w1=torch.tensor(0.01,dtype=torch.float64,requires_grad=True)\n",
    "w2=torch.tensor(0.01,dtype=torch.float64,requires_grad=True)\n",
    "L=nn.MSELoss()\n",
    "for i in range(20):\n",
    "    Y_hat=3*((w0*a)+((w1*b)*(w2*c)))\n",
    "    err=L(Y_hat,Y)\n",
    "    err.backward()\n",
    "    with torch.no_grad():\n",
    "        w0.add_(-lr*w0.grad)\n",
    "        w1.add_(-lr*w1.grad)\n",
    "        w2.add_(-lr*w2.grad)\n",
    "        \n",
    "    \n",
    "    w0.grad.zero_()\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "    if(i %2 ==0):\n",
    "        \n",
    "        print(f'epoch {i +1}:weight0 = {w0:.3f}, weight1 = {w1:.3f} , weight2 = {w2:.3f}  ,loss = {err:0.5f}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "191d536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.004999999999995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*(2.194*5+3*0.073+2*0.073)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25d20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e26651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c7810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39328902",
   "metadata": {},
   "outputs": [],
   "source": [
    "agrad=None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e77c4644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1:a = 1.162, b = 1.162 , c = 1.162  ,loss = 729.00000\n",
      "\n",
      "epoch 3:a = 1.457, b = 1.530 , c = 1.530  ,loss = 560.39389\n",
      "\n",
      "epoch 5:a = 1.702, b = 1.928 , c = 1.928  ,loss = 371.76733\n",
      "\n",
      "epoch 7:a = 1.887, b = 2.301 , c = 2.301  ,loss = 198.44446\n",
      "\n",
      "epoch 9:a = 2.010, b = 2.592 , c = 2.592  ,loss = 80.81125\n",
      "\n",
      "epoch 11:a = 2.081, b = 2.779 , c = 2.779  ,loss = 25.12565\n",
      "\n",
      "epoch 13:a = 2.117, b = 2.882 , c = 2.882  ,loss = 6.32998\n",
      "\n",
      "epoch 15:a = 2.135, b = 2.932 , c = 2.932  ,loss = 1.39838\n",
      "\n",
      "epoch 17:a = 2.143, b = 2.956 , c = 2.956  ,loss = 0.28807\n",
      "\n",
      "epoch 19:a = 2.147, b = 2.967 , c = 2.967  ,loss = 0.05737\n",
      "\n",
      "epoch 21:a = 2.148, b = 2.971 , c = 2.971  ,loss = 0.01125\n",
      "\n",
      "epoch 23:a = 2.149, b = 2.973 , c = 2.973  ,loss = 0.00219\n",
      "\n",
      "epoch 25:a = 2.149, b = 2.974 , c = 2.974  ,loss = 0.00043\n",
      "\n",
      "epoch 27:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00008\n",
      "\n",
      "epoch 29:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00002\n",
      "\n",
      "epoch 31:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 33:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 35:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 37:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 39:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 41:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 43:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 45:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 47:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 49:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 51:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 53:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 55:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 57:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 59:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 61:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 63:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 65:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 67:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 69:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 71:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 73:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 75:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 77:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 79:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 81:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 83:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 85:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 87:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 89:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 91:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 93:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 95:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 97:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 99:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 101:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 103:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 105:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 107:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 109:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 111:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 113:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 115:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 117:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n",
      "\n",
      "epoch 119:a = 2.149, b = 2.975 , c = 2.975  ,loss = 0.00000\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(1,dtype=torch.float64,requires_grad=True) #i will consider those as training data\n",
    "b=torch.tensor(1,dtype=torch.float64,requires_grad=True)\n",
    "c=torch.tensor(1,dtype=torch.float64,requires_grad=True)\n",
    "\n",
    "Y=torch.tensor(33,dtype=torch.float64)\n",
    "L=nn.MSELoss()\n",
    "for i in range(120):\n",
    "    u=b*c\n",
    "    v=a+u\n",
    "    Y_hat=3*v\n",
    "    err=L(Y_hat,Y)\n",
    "    err.backward(retain_graph=True)\n",
    "    with torch.no_grad():\n",
    "        a.add_(-lr*a.grad)\n",
    "        b.add_(-lr*b.grad)\n",
    "        c.add_(-lr*c.grad)\n",
    "        agrad=a.grad\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    c.grad.zero_()\n",
    "    if(i %2 ==0):\n",
    "        print()\n",
    "        print(f'epoch {i +1}:a = {a:.3f}, b = {b:.3f} , c = {c:.3f}  ,loss = {err:0.5f}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd487e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.998875000000005"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat=3*(2.149+(2.975*2.975))\n",
    "Y_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e39f2",
   "metadata": {},
   "source": [
    "# Simple Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a05c3d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:w = 0.045, b = 0.022 , loss = 40.53135\n",
      "epoch 3:w = 0.113, b = 0.045 , loss = 37.89168\n",
      "epoch 5:w = 0.178, b = 0.068 , loss = 35.42396\n",
      "epoch 7:w = 0.242, b = 0.089 , loss = 33.11702\n",
      "epoch 9:w = 0.303, b = 0.111 , loss = 30.96037\n",
      "epoch 11:w = 0.362, b = 0.131 , loss = 28.94421\n",
      "epoch 13:w = 0.420, b = 0.151 , loss = 27.05940\n",
      "epoch 15:w = 0.475, b = 0.170 , loss = 25.29739\n",
      "epoch 17:w = 0.529, b = 0.188 , loss = 23.65016\n",
      "epoch 19:w = 0.581, b = 0.206 , loss = 22.11024\n",
      "epoch 21:w = 0.631, b = 0.223 , loss = 20.67064\n",
      "epoch 23:w = 0.679, b = 0.240 , loss = 19.32484\n",
      "epoch 25:w = 0.726, b = 0.256 , loss = 18.06670\n",
      "epoch 27:w = 0.771, b = 0.271 , loss = 16.89053\n",
      "epoch 29:w = 0.815, b = 0.287 , loss = 15.79098\n",
      "epoch 31:w = 0.857, b = 0.301 , loss = 14.76307\n",
      "epoch 33:w = 0.898, b = 0.315 , loss = 13.80211\n",
      "epoch 35:w = 0.938, b = 0.329 , loss = 12.90377\n",
      "epoch 37:w = 0.976, b = 0.342 , loss = 12.06394\n",
      "epoch 39:w = 1.013, b = 0.355 , loss = 11.27883\n",
      "epoch 41:w = 1.049, b = 0.367 , loss = 10.54487\n",
      "epoch 43:w = 1.083, b = 0.379 , loss = 9.85872\n",
      "epoch 45:w = 1.117, b = 0.391 , loss = 9.21726\n",
      "epoch 47:w = 1.149, b = 0.402 , loss = 8.61760\n",
      "epoch 49:w = 1.180, b = 0.413 , loss = 8.05700\n",
      "epoch 51:w = 1.211, b = 0.423 , loss = 7.53293\n",
      "epoch 53:w = 1.240, b = 0.433 , loss = 7.04299\n",
      "epoch 55:w = 1.268, b = 0.443 , loss = 6.58498\n",
      "epoch 57:w = 1.295, b = 0.452 , loss = 6.15680\n",
      "epoch 59:w = 1.322, b = 0.462 , loss = 5.75651\n",
      "epoch 61:w = 1.347, b = 0.470 , loss = 5.38230\n",
      "epoch 63:w = 1.372, b = 0.479 , loss = 5.03247\n",
      "epoch 65:w = 1.396, b = 0.487 , loss = 4.70543\n",
      "epoch 67:w = 1.419, b = 0.495 , loss = 4.39969\n",
      "epoch 69:w = 1.441, b = 0.503 , loss = 4.11387\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y=torch.tensor([3,5,7,9],dtype=torch.float32)\n",
    "w=torch.tensor(0.01,dtype=torch.float32,requires_grad=True)\n",
    "b=torch.tensor(0.01,dtype=torch.float32,requires_grad=True)\n",
    "loss=nn.MSELoss() \n",
    "for i in range(70):\n",
    "    y_pred=w*x+b\n",
    "    l=loss(Y,y_pred)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w.add_(-lr*w.grad)\n",
    "        b.add_(-lr*b.grad)\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    if(i %2 ==0):\n",
    "        print(f'epoch {i +1}:w = {w:.3f}, b = {b:.3f} , loss = {l:0.5f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3290b79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7912"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*1.1441+0.503"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fb81c",
   "metadata": {},
   "source": [
    "# Start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "174cbc9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:weights = nan  ,loss = nan\n",
      "epoch 3:weights = nan  ,loss = nan\n",
      "epoch 5:weights = nan  ,loss = nan\n",
      "epoch 7:weights = nan  ,loss = nan\n",
      "epoch 9:weights = nan  ,loss = nan\n",
      "epoch 11:weights = nan  ,loss = nan\n",
      "epoch 13:weights = nan  ,loss = nan\n",
      "epoch 15:weights = nan  ,loss = nan\n"
     ]
    }
   ],
   "source": [
    "def forward(a,b,c):\n",
    "    return 3*(w0*a+(w1*b*w2*c))\n",
    "\n",
    "def loss(y,y_hat): #mean square error\n",
    "    return ((y-y_hat)**2).mean() #the size of all input should be the same so i picked anything here\n",
    "\n",
    "lr=0.01\n",
    "iteration=15\n",
    "\n",
    "for epoch in range(iteration):\n",
    "    \n",
    "    y_hat=forward(a,b,c)\n",
    "    l=loss(Y,y_hat)\n",
    "    #backward propgation is here\n",
    "    l.backward(retain_graph=True)\n",
    "    with torch.no_grad():\n",
    "        w0.add_(-lr*w0.grad)\n",
    "        w1.add_(-lr*w1.grad)\n",
    "        w2.add_(-lr*w2.grad)       \n",
    "        \n",
    "    w0.grad.zero_()\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "    if(epoch %2 ==0):\n",
    "        print(f'epoch {epoch +1}:weights = {w0:.3f}  ,loss = {l:0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fe40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
